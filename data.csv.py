"""
[课程内容]: Python实现B站Up视频数据信息采集, 实现可视化数据分析 <内含JS逆向解密>

[授课老师]: 青灯教育-自游 [上课时间]: 20:05 可以问问题 可以点歌

[环境使用]:
    Python 3.8
    Pycharm

[模块使用]:
    import requests
    import csv
    import datetime
    import hashlib
    import time
---------------------------------------------------------------------------------------------------
win + R 输入cmd 输入安装命令 pip install 模块名 (如果你觉得安装速度比较慢, 你可以切换国内镜像源)
先听一下歌 等一下后面进来的同学,20:05正式开始讲课 [有什么喜欢听得歌曲 也可以在公屏发一下]
相对应的安装包/安装教程/激活码/使用教程/学习资料/工具插件 可以加落落老师微信
---------------------------------------------------------------------------------------------------

写过爬虫 --> 1
没有写过 --> 0

对于本节课讲解的内容, 有任何不懂的地方都可以直接问

爬虫实现基本流程:

一. 数据来源分析
    1. 明确需求
        - 明确采集网站以及数据
            网址: https://space.bilibili.com/517327498/video?tid=0&pn=2&keyword=&order=pubdate
            数据: 视频基本信息: 标题 播放量 评论 弹幕 上传时间 ...
    2. 抓包分析
        - 打开开发者工具: F12 / 右键点击检查选择network
        - 点击网页下一页 --> XHR 第一条数据包就是我们需要的内容
    数据包: https://api.bilibili.com/x/space/wbi/arc/search?mid=517327498&ps=30&tid=0&pn=3&keyword=&order=pubdate&platform=web&web_location=1550101&order_avoided=true&w_rid=c9a9f931486961175b1e8138d695680e&wts=1690027894

二. 代码实现步骤 <固定四个大步骤>
    1. 发送请求, 模拟浏览器对于url地址发送请求
        请求链接: 数据包链接
    2. 获取数据, 获取服务器返回响应数据
        开发者工具: response
    3. 解析数据, 提取我们需要的数据内容
        视频基本信息
    4. 保存数据, 把信息数据保存表格文件

学习python, 不需要记单词, 去了解语法规则 了解模块使用
    1. 代码都有智能提示
    2. 写多了自然就会了
    3. 编程开卷, 不是闭卷
    4. 常用单词词汇并不多 --> 135+左右
    
以后日常工作, 有遇到问题, 都可以查阅资料


免费公开课以外, 还有专门付费系统课程

课程内容:
    核心编程 爬虫开发 数据分析 网站开发 人工智能 自动化办公

加婧琪老师微信: python1018
    1. 免费领取课程学习路线图
    2. 给你量身定制你学习方向以及规划

你的学习目的不同, 你学习方向是有一定区别

1. 兴趣爱好
    学习方向: 核心编程+爬虫开发
    跟着老师系统学习:
        10节左右知识点内容, 可以公开课讲解案例水平
        <公开课讲的案例都可以实现>

2. 兼职外包
    外包订单爬虫和数据分析居多
        学习方向: 核心编程+爬虫开发+数据分析
    跟着老师系统学习:
        最短2个月左右时间, 学完爬虫之后, 可以接外包
    外包价格: 200-5000左右不等
    在线学生接外包月收: 1000-3000左右
    平均一周接一个外包, 一个外包200左右, 一个月1000左右收入

3. 就业工作 职业发展
    面向企业招聘需求学习
    学习方向: 核心编程+爬虫开发+数据分析+网站开发+人工智能+<自动化办公>
    岗位:
        爬虫工程师 数据分析师 开发工程师 算法工程师
    薪资待遇:
        应届生: 8000-15000左右
        1-3年: 15000-25000左右
        3-5年: 25000-35000左右
        5年以上: 30000+左右

老师保证你能够学会掌握...
    按时听课: 坚持学习
    按时完成作业: 多敲多练
    认真学习: 不懂多问

咱们课程服务从入学 --> 学完 都有相应服务
    - 直播授课
        一周三节课, 晚上 20:00-22:00
    - 课后 录播 源码 笔记 文档 软件工具 作业 考核
        <课程资料可以永久观看学习>
    - 老师解答辅导, 5v1解答
        文字 语音 远程操作
        任何时间都可以找我解答辅导, 只要我看到消息都回你
    - 班主任监督学习, 电话通知听课
    - 免费重修 <对于零基础福音>
        一遍不扎实, 可以学两遍
        两遍不扎实, 可以学三遍
        三遍不扎实, 基本不可能
    - 外包指导
        提供外包接单平台 渠道 外包解答辅导
            傻瓜式接单 --> 你要接单 找老师, 带你接单即可
    - 就业指导
        企业简历修改和制作, 面试试题, 面试技巧

    - 培训合同 发票

课程学费:
    核心编程: 2260
    爬虫开发: 2980
    数据分析: 2180
    网站开发: 2980
    人工智能: 2680
    自动化办公: 1680
总计学费: 14760

加婧琪老师微信: python1018
    <只要你加了婧琪老师微信, 就可以获取优惠减免>

学费优惠减免:
    一. 高薪就业班级:
        核心编程+爬虫开发+数据分析+网站开发+人工智能+<自动化办公>
        原价学费: 14760 --> 优惠到 8880 学费
    二. 兼职外包班级:
        核心编程+爬虫开发+数据分析+ 额外赠送 自动化办公
        原价学费 7420+1680= 9100 ---> 优惠到 6680

学费方面有压力, 还是学生
    1. 可以和父母商量一下, 父母都会支持你学习
    2. 不想靠父母,我想自己努力学好接单赚学费

申请0元入学,学费可以按月支付
    一. 高薪就业班级:
        8880 / 6 = 1,480
        8880 / 12 = 740
        8880 / 18 = 493
        8880 / 24 = 370
    二. 兼职外包班级
        6680 / 6 = 1,113
        6680 / 12 = 556
        6680 / 18 = 371

平均计算, 一天一杯奶茶钱就可以跟着老师学习了

今天报名, 可以不需要支付任何学费, 直接进班跟着老师学习
    8月22号, 支付第一个月学费 370
    9月22号, 支付第二个月学费 370

如果你想要接单, 最短2个月左右的时间, 学完爬虫之后, 可以接单
    370 --> 相当于一个月接1-2外包左右, 学费就回来了

暑假的时候 寒假的时候, 就可以出去旅游, 看看大好河山...

学习技术 --> 提升自己个人能力 --> 提升自己生活品质


学费压力?
时间不足?
担心没办法掌握?
后续外包接单问题?

学完系统课能实现兼职不?
    问完爬虫就可以了, 开始兼职
    2个月左右时间 --> 先学核心编程基础 在学爬虫开发
会提供外包订单

课程资料是可以直接观看学习
    提供免费重修

"""
import time

# 导入数据请求模块 第三方模块 需要安装
import requests
# 导入格式化输出模块
from pprint import pprint
import datetime
# 导入csv模块
import csv
import hashlib

f = open('信息.csv', mode='w', encoding='utf-8', newline='')
csv_writer = csv.DictWriter(f, fieldnames=[
    '标题',
    '描述',
    'BV号',
    '播放量',
    '弹幕',
    '评论',
    '时长',
    '上传时间',
])
csv_writer.writeheader()
"""
1. 发送请求, 模拟浏览器对于url地址发送请求
    请求链接: 数据包链接
    
- 模拟浏览器: headers 请求头
    字典数据类型, 构建完整键值对形式
    
- 请求链接:
    请求链接和请求参数分开写
        问号前面: 请求链接
        问号后面: 请求参数/查询参数
    批量替换:
        1. 选择替换内容, ctrl+R
        2. 输入正则命令进行匹配替换
            (.*?): (.*)
            '$1': '$2',
            
多写的数据采集 --> 分析请求链接参数变化规律
"""

# 模拟浏览器 -> 基本反反爬虫措施
headers = {
    # 用户代理 表示浏览器基本身份信息
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'
}
for page in range(1, 11):
    string = f'keyword=&mid=517327498&order=pubdate&order_avoided=true&platform=web&pn={page}&ps=30&tid=0&web_location=1550101&wts={int(time.time())}6eff17696695c344b67618ac7b114f92'
    # 实例化对象
    md5_hash = hashlib.md5()
    md5_hash.update(string.encode('utf-8'))
    # 请求链接
    url = 'https://api.bilibili.com/x/space/wbi/arc/search'
    # 请求参数
    data = {
        'mid': '517327498',
        'ps': '30',
        'tid': '0',
        'pn': page,
        'keyword': '',
        'order': 'pubdate',
        'platform': 'web',
        'web_location': '1550101',
        'order_avoided': 'true',
        'w_rid': md5_hash.hexdigest(),
        'wts': int(time.time()),
    }
    # 发送请求 <Response [200]> 响应对象 表示请求成功
    response = requests.get(url=url, params=data, headers=headers)
    """
    2. 获取数据, 获取服务器返回响应数据
        开发者工具: response
    
    获取响应数据:
        - response.json() 获取响应json数据
            <字典数据类型>
        - response.text 获取响应文本数据
            <网页源代码 字符串数据>
        - response.content 获取响应二进制数据数据
            <获取图片/视频/音频/特定格式文件>
    
    3. 解析数据, 提取我们需要的数据内容
        视频基本信息
    
    字典数据 --> 键值对取值
        根据冒号左边的内容[键], 提取冒号右边的内容[值]
    
    response.json()['data']['list']['vlist'] --> 返回列表
        列表里面包含整个网页视频信息 <N个视频内容>
    
    列表 / 字典 / 集合 / 元组 --> 数据容器 <装东西的盒子>
    
        lis = [1, 2, 3, 4, 5] --> for循环遍历, 把列表里面内容一个一个单独提取
    for li in lis:
        # 从lis这个盒子里面, 把元素<东西> 拿出来, 用li变量接收
    
    print(index)    输入一行效果
    pprint(index)   多行展开效果
    """
    for index in response.json()['data']['list']['vlist']:
        # 时间戳 时间节点 --> 上传视频时间点
        date = index['created']
        dt = datetime.datetime.fromtimestamp(date)
        dt_time = dt.strftime('%Y-%m-%d')
        dit = {
            '标题': index['title'],
            '描述': index['description'],
            'BV号': index['bvid'],
            '播放量': index['play'],
            '弹幕': index['video_review'],
            '评论': index['comment'],
            '时长': index['length'],
            '上传时间': dt_time,
        }
        # 写入数据
        csv_writer.writerow(dit)
        print(dit)
